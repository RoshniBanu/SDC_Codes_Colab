{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "AI POWERED LANGUAGE TRANSLATOR"
      ],
      "metadata": {
        "id": "SAwPOWWcZMq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imSQiLhVZMDj",
        "outputId": "de4d765f-c03a-4c56-ff49-da7b02db3fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåê AI Language Translator\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Translate *from* (e.g., en, fr, de): en\n",
            "Translate *to* (e.g., fr, en, de): fr\n",
            "üîÑ Loading model for 'en' ‚û°Ô∏è 'fr' (please wait...)\n",
            "\n",
            "‚úÖ Translator ready! Enter text to translate:\n",
            "\n",
            "You: how are you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4106: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Translation: Comment allez-vous ?\n",
            "--------------------------------------------------\n",
            "You: exit\n",
            "üëã Exiting translator.\n"
          ]
        }
      ],
      "source": [
        "# language_translator.py\n",
        "\n",
        "# ‚úÖ Step 1: Auto-install required packages\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    from transformers import MarianMTModel, MarianTokenizer\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"sentencepiece\"])\n",
        "    from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# ‚úÖ Step 2: Silence Hugging Face download progress\n",
        "import os\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"  # Hide loading bars\n",
        "\n",
        "# ‚úÖ Step 3: Load model\n",
        "def load_translation_model(src_lang=\"en\", tgt_lang=\"fr\"):\n",
        "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
        "    print(f\"üîÑ Loading model for '{src_lang}' ‚û°Ô∏è '{tgt_lang}' (please wait...)\")\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name, use_auth_token=None)\n",
        "    model = MarianMTModel.from_pretrained(model_name, use_auth_token=None)\n",
        "    return tokenizer, model\n",
        "\n",
        "# ‚úÖ Step 4: Translate\n",
        "def translate(text, tokenizer, model):\n",
        "    if not text.strip():\n",
        "        return \"‚ö†Ô∏è Please enter some text.\"\n",
        "    try:\n",
        "        encoded = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\", padding=True)\n",
        "        output = model.generate(**encoded)\n",
        "        return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\"\n",
        "\n",
        "# ‚úÖ Step 5: Main\n",
        "def main():\n",
        "    print(\"üåê AI Language Translator\")\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "\n",
        "    src_lang = input(\"Translate *from* (e.g., en, fr, de): \").strip().lower()\n",
        "    tgt_lang = input(\"Translate *to* (e.g., fr, en, de): \").strip().lower()\n",
        "\n",
        "    try:\n",
        "        tokenizer, model = load_translation_model(src_lang, tgt_lang)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not load model: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n‚úÖ Translator ready! Enter text to translate:\\n\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            text = input(\"You: \")\n",
        "            if text.lower() in [\"exit\", \"quit\"]:\n",
        "                print(\"üëã Exiting translator.\")\n",
        "                break\n",
        "\n",
        "            translated = translate(text, tokenizer, model)\n",
        "            print(\"üîÅ Translation:\", translated)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Exiting translator.\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}